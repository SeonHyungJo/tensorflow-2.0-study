{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ch07 순환 신경망.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOBuH9qrYOWAg/GMFGyPQKh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SeonHyungJo/tensorflow-2.0-study/blob/master/%ED%85%90%EC%84%9C%ED%94%8C%EB%A1%9C_2.0_%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/Ch07_%EC%88%9C%ED%99%98_%EC%8B%A0%EA%B2%BD%EB%A7%9D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZewMV74PYOf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "d1a2eb5e-b4d5-461d-bf49-696978a1e590"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# 신경망 예측 데이터 생성\n",
        "X = []\n",
        "Y = []\n",
        "\n",
        "for i in range(6):\n",
        "  #  [0,1,2,3], [1,2,3,4] 같은 정수의 시퀀스를 만든다.\n",
        "  lst = list(range(i,i+4))\n",
        "\n",
        "  print('lst', lst)\n",
        "\n",
        "  # 위에서 구한 시퀀스의 숫자들을 각각 10으로 나눈 다음 저장한다.\n",
        "  # SimpleRNN에 각 타임스텝에 하나씩 숫자가 들어가기 때문에 여기서도 하나씩 분리해서 배열에 저장한다.\n",
        "  X.append(list(map(lambda c: [c/10], lst)))\n",
        "\n",
        "  # 정답에 해당하는 4,5 등의 정수 역시 앞에서처럼 10으로 나누어서 저장한다.\n",
        "  Y.append((i+4)/10)\n",
        "\n",
        "X = np.array(X)\n",
        "Y = np.array(Y)\n",
        "for i in range(len(X)):\n",
        "  print(X[i], Y[i])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lst [0, 1, 2, 3]\n",
            "lst [1, 2, 3, 4]\n",
            "lst [2, 3, 4, 5]\n",
            "lst [3, 4, 5, 6]\n",
            "lst [4, 5, 6, 7]\n",
            "lst [5, 6, 7, 8]\n",
            "[[0. ]\n",
            " [0.1]\n",
            " [0.2]\n",
            " [0.3]] 0.4\n",
            "[[0.1]\n",
            " [0.2]\n",
            " [0.3]\n",
            " [0.4]] 0.5\n",
            "[[0.2]\n",
            " [0.3]\n",
            " [0.4]\n",
            " [0.5]] 0.6\n",
            "[[0.3]\n",
            " [0.4]\n",
            " [0.5]\n",
            " [0.6]] 0.7\n",
            "[[0.4]\n",
            " [0.5]\n",
            " [0.6]\n",
            " [0.7]] 0.8\n",
            "[[0.5]\n",
            " [0.6]\n",
            " [0.7]\n",
            " [0.8]] 0.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyYaKIDeQwgn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "873d2983-c4b3-482f-d90b-d601ca1d7b7d"
      },
      "source": [
        "# 시퀀스 예측 모델 정의\n",
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.SimpleRNN(units=10, return_sequences=False, input_shape=[4,1]),\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "model.summary()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "simple_rnn (SimpleRNN)       (None, 10)                120       \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 131\n",
            "Trainable params: 131\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTGs1OIORod8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "fcff6097-92b5-4805-c510-c22770a9a83e"
      },
      "source": [
        "# 네트워크 훈련 및 결과 확인\n",
        "model.fit(X, Y, epochs=100, verbose=0)\n",
        "print(model.predict(X))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.35729402]\n",
            " [0.51261634]\n",
            " [0.63831216]\n",
            " [0.7341382 ]\n",
            " [0.80362856]\n",
            " [0.8517923 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8MLZkQ4SxB9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "7148be26-05aa-4b1e-d339-8fc926441299"
      },
      "source": [
        "# 학습되지 않은 시퀀스에 대한 예측 결과\n",
        "print(model.predict(np.array([[[0.6], [0.7], [0.8], [0.9]]])))\n",
        "print(model.predict(np.array([[[-0.1], [0.0], [0.1], [0.2]]])))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.88361263]]\n",
            "[[0.17855123]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZPKnRc9W0_c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2510d6ae-5aab-4bbc-f319-5ebbed4531b0"
      },
      "source": [
        "# 곱셈 문제 데이터 생성\n",
        "X = []\n",
        "Y = []\n",
        "for i in range(3000):\n",
        "  # 0 ~ 1 범위의 랜덤한 숫자 100개를 만든다.\n",
        "  lst = np.random.rand(100)\n",
        "\n",
        "  # 마킹할 숫자 2개의 인덱스를 뽑는다.\n",
        "  idx = np.random.choice(100, 2, replace=False)\n",
        "\n",
        "  # 마킹 인덱스가 저장된 원=핫 인코딩 벡터를 만든다.\n",
        "  zeros = np.zeros(100)\n",
        "  zeros[idx] = 1\n",
        "\n",
        "  # 마킹 인덱스와 랜덤한 숫자를 햡쳐서 X에 저장합니다.\n",
        "  X.append(np.array(list(zip(zeros, lst)))) \n",
        "  # 마킹 인덱스가 1인 값만 서로 곱해서 Y에 저장합니다.\n",
        "  Y.append(np.prod(lst[idx]))\n",
        "\n",
        "print(X[0], Y[0])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.         0.07406413]\n",
            " [0.         0.18620492]\n",
            " [0.         0.19019044]\n",
            " [0.         0.38005243]\n",
            " [0.         0.03554939]\n",
            " [0.         0.99490898]\n",
            " [0.         0.4560137 ]\n",
            " [1.         0.37330382]\n",
            " [0.         0.7916733 ]\n",
            " [0.         0.40139998]\n",
            " [0.         0.13435771]\n",
            " [0.         0.14136544]\n",
            " [0.         0.40936744]\n",
            " [0.         0.80662415]\n",
            " [0.         0.93874669]\n",
            " [0.         0.48410569]\n",
            " [0.         0.08701132]\n",
            " [0.         0.18880749]\n",
            " [0.         0.24296099]\n",
            " [0.         0.36903031]\n",
            " [0.         0.23310985]\n",
            " [0.         0.08697399]\n",
            " [0.         0.86492873]\n",
            " [0.         0.22366286]\n",
            " [0.         0.04831   ]\n",
            " [0.         0.32975171]\n",
            " [0.         0.8384756 ]\n",
            " [0.         0.67327374]\n",
            " [0.         0.15958238]\n",
            " [0.         0.5938906 ]\n",
            " [0.         0.711938  ]\n",
            " [0.         0.25506535]\n",
            " [0.         0.90858829]\n",
            " [0.         0.11533055]\n",
            " [0.         0.4241082 ]\n",
            " [0.         0.31393863]\n",
            " [0.         0.70403434]\n",
            " [0.         0.38263309]\n",
            " [0.         0.87087158]\n",
            " [0.         0.40318239]\n",
            " [0.         0.625822  ]\n",
            " [0.         0.93027875]\n",
            " [0.         0.36270674]\n",
            " [0.         0.42971623]\n",
            " [0.         0.67807267]\n",
            " [0.         0.928264  ]\n",
            " [0.         0.43735142]\n",
            " [0.         0.39136121]\n",
            " [0.         0.44576515]\n",
            " [0.         0.95959949]\n",
            " [0.         0.2538391 ]\n",
            " [0.         0.15618545]\n",
            " [0.         0.44744273]\n",
            " [0.         0.59275909]\n",
            " [0.         0.74070941]\n",
            " [0.         0.73570079]\n",
            " [0.         0.61234623]\n",
            " [0.         0.33347418]\n",
            " [0.         0.98112778]\n",
            " [0.         0.88465281]\n",
            " [0.         0.95874753]\n",
            " [0.         0.3115289 ]\n",
            " [0.         0.86161067]\n",
            " [0.         0.77249001]\n",
            " [0.         0.2888916 ]\n",
            " [0.         0.80984039]\n",
            " [0.         0.03415365]\n",
            " [0.         0.21171666]\n",
            " [0.         0.17060622]\n",
            " [0.         0.36745378]\n",
            " [0.         0.46538483]\n",
            " [0.         0.84776193]\n",
            " [0.         0.05467395]\n",
            " [0.         0.10934946]\n",
            " [0.         0.98081111]\n",
            " [0.         0.26871698]\n",
            " [0.         0.05900484]\n",
            " [0.         0.93560075]\n",
            " [0.         0.2988809 ]\n",
            " [0.         0.73924164]\n",
            " [0.         0.70910506]\n",
            " [1.         0.2136989 ]\n",
            " [0.         0.53902247]\n",
            " [0.         0.63997732]\n",
            " [0.         0.38282093]\n",
            " [0.         0.21698414]\n",
            " [0.         0.21680498]\n",
            " [0.         0.73274744]\n",
            " [0.         0.93215611]\n",
            " [0.         0.00811614]\n",
            " [0.         0.11913559]\n",
            " [0.         0.23440656]\n",
            " [0.         0.78890528]\n",
            " [0.         0.34017521]\n",
            " [0.         0.82109926]\n",
            " [0.         0.25788944]\n",
            " [0.         0.59994529]\n",
            " [0.         0.04240163]\n",
            " [0.         0.21456523]\n",
            " [0.         0.05166449]] 0.07977461506023413\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yawapz1-Xu_c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "e50d5c87-94bb-4609-ade2-cd1d269e787d"
      },
      "source": [
        "# SimpleRNN  레이어를 이용한 곱셈 문제 모델 정의\n",
        "model = tf.keras.Sequential([\n",
        " tf.keras.layers.SimpleRNN(units=30, return_sequences=True, input_shape=[100,2]),\n",
        " tf.keras.layers.SimpleRNN(units=30)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "model.summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "simple_rnn_1 (SimpleRNN)     (None, 100, 30)           990       \n",
            "_________________________________________________________________\n",
            "simple_rnn_2 (SimpleRNN)     (None, 30)                1830      \n",
            "=================================================================\n",
            "Total params: 2,820\n",
            "Trainable params: 2,820\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFyWkD6qYNTO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e2c2524c-0dea-4d57-d62f-868f181a4f75"
      },
      "source": [
        "# SimpleRNN 네트워크 학습\n",
        "X = np.array(X)\n",
        "Y = np.array(Y)\n",
        "\n",
        "history = model.fit(X[:2560], Y[:2560], epochs=100, validation_split=0.2)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "64/64 [==============================] - 9s 142ms/step - loss: 0.1300 - val_loss: 0.0658\n",
            "Epoch 2/100\n",
            "64/64 [==============================] - 9s 136ms/step - loss: 0.0589 - val_loss: 0.0510\n",
            "Epoch 3/100\n",
            "64/64 [==============================] - 9s 136ms/step - loss: 0.0536 - val_loss: 0.0495\n",
            "Epoch 4/100\n",
            "64/64 [==============================] - 9s 143ms/step - loss: 0.0526 - val_loss: 0.0502\n",
            "Epoch 5/100\n",
            "64/64 [==============================] - 9s 138ms/step - loss: 0.0528 - val_loss: 0.0482\n",
            "Epoch 6/100\n",
            "64/64 [==============================] - 9s 137ms/step - loss: 0.0517 - val_loss: 0.0480\n",
            "Epoch 7/100\n",
            "64/64 [==============================] - 9s 137ms/step - loss: 0.0515 - val_loss: 0.0480\n",
            "Epoch 8/100\n",
            "64/64 [==============================] - 9s 136ms/step - loss: 0.0515 - val_loss: 0.0486\n",
            "Epoch 9/100\n",
            "64/64 [==============================] - 9s 139ms/step - loss: 0.0516 - val_loss: 0.0477\n",
            "Epoch 10/100\n",
            "64/64 [==============================] - 9s 139ms/step - loss: 0.0513 - val_loss: 0.0479\n",
            "Epoch 11/100\n",
            "64/64 [==============================] - 9s 138ms/step - loss: 0.0513 - val_loss: 0.0481\n",
            "Epoch 12/100\n",
            "64/64 [==============================] - 9s 138ms/step - loss: 0.0513 - val_loss: 0.0493\n",
            "Epoch 13/100\n",
            "64/64 [==============================] - 9s 137ms/step - loss: 0.0517 - val_loss: 0.0476\n",
            "Epoch 14/100\n",
            "64/64 [==============================] - 9s 147ms/step - loss: 0.0513 - val_loss: 0.0475\n",
            "Epoch 15/100\n",
            "64/64 [==============================] - 9s 138ms/step - loss: 0.0515 - val_loss: 0.0479\n",
            "Epoch 16/100\n",
            "64/64 [==============================] - 9s 138ms/step - loss: 0.0512 - val_loss: 0.0475\n",
            "Epoch 17/100\n",
            "64/64 [==============================] - 9s 137ms/step - loss: 0.0515 - val_loss: 0.0477\n",
            "Epoch 18/100\n",
            "64/64 [==============================] - 9s 139ms/step - loss: 0.0514 - val_loss: 0.0477\n",
            "Epoch 19/100\n",
            "64/64 [==============================] - 9s 138ms/step - loss: 0.0512 - val_loss: 0.0479\n",
            "Epoch 20/100\n",
            "64/64 [==============================] - 9s 135ms/step - loss: 0.0512 - val_loss: 0.0474\n",
            "Epoch 21/100\n",
            "64/64 [==============================] - 9s 136ms/step - loss: 0.0512 - val_loss: 0.0479\n",
            "Epoch 22/100\n",
            "64/64 [==============================] - 9s 135ms/step - loss: 0.0513 - val_loss: 0.0476\n",
            "Epoch 23/100\n",
            "64/64 [==============================] - 9s 135ms/step - loss: 0.0513 - val_loss: 0.0473\n",
            "Epoch 24/100\n",
            "64/64 [==============================] - 9s 133ms/step - loss: 0.0513 - val_loss: 0.0477\n",
            "Epoch 25/100\n",
            "64/64 [==============================] - 9s 135ms/step - loss: 0.0513 - val_loss: 0.0480\n",
            "Epoch 26/100\n",
            "64/64 [==============================] - 9s 134ms/step - loss: 0.0516 - val_loss: 0.0474\n",
            "Epoch 27/100\n",
            "64/64 [==============================] - 9s 133ms/step - loss: 0.0512 - val_loss: 0.0479\n",
            "Epoch 28/100\n",
            "64/64 [==============================] - 9s 133ms/step - loss: 0.0510 - val_loss: 0.0475\n",
            "Epoch 29/100\n",
            "64/64 [==============================] - 9s 135ms/step - loss: 0.0511 - val_loss: 0.0473\n",
            "Epoch 30/100\n",
            "64/64 [==============================] - 9s 135ms/step - loss: 0.0513 - val_loss: 0.0482\n",
            "Epoch 31/100\n",
            "64/64 [==============================] - 9s 136ms/step - loss: 0.0511 - val_loss: 0.0475\n",
            "Epoch 32/100\n",
            "64/64 [==============================] - 9s 133ms/step - loss: 0.0511 - val_loss: 0.0476\n",
            "Epoch 33/100\n",
            "64/64 [==============================] - 9s 135ms/step - loss: 0.0511 - val_loss: 0.0474\n",
            "Epoch 34/100\n",
            "64/64 [==============================] - 9s 135ms/step - loss: 0.0513 - val_loss: 0.0475\n",
            "Epoch 35/100\n",
            "64/64 [==============================] - 9s 134ms/step - loss: 0.0511 - val_loss: 0.0475\n",
            "Epoch 36/100\n",
            "64/64 [==============================] - 9s 136ms/step - loss: 0.0514 - val_loss: 0.0474\n",
            "Epoch 37/100\n",
            "64/64 [==============================] - 9s 134ms/step - loss: 0.0510 - val_loss: 0.0479\n",
            "Epoch 38/100\n",
            "64/64 [==============================] - 9s 138ms/step - loss: 0.0511 - val_loss: 0.0477\n",
            "Epoch 39/100\n",
            "64/64 [==============================] - 9s 136ms/step - loss: 0.0510 - val_loss: 0.0477\n",
            "Epoch 40/100\n",
            "64/64 [==============================] - 9s 135ms/step - loss: 0.0512 - val_loss: 0.0473\n",
            "Epoch 41/100\n",
            "64/64 [==============================] - 9s 134ms/step - loss: 0.0509 - val_loss: 0.0473\n",
            "Epoch 42/100\n",
            "64/64 [==============================] - 9s 134ms/step - loss: 0.0509 - val_loss: 0.0475\n",
            "Epoch 43/100\n",
            "64/64 [==============================] - 9s 134ms/step - loss: 0.0510 - val_loss: 0.0481\n",
            "Epoch 44/100\n",
            "64/64 [==============================] - 9s 136ms/step - loss: 0.0510 - val_loss: 0.0474\n",
            "Epoch 45/100\n",
            "64/64 [==============================] - 9s 134ms/step - loss: 0.0512 - val_loss: 0.0475\n",
            "Epoch 46/100\n",
            "64/64 [==============================] - 9s 135ms/step - loss: 0.0511 - val_loss: 0.0479\n",
            "Epoch 47/100\n",
            "64/64 [==============================] - 9s 135ms/step - loss: 0.0512 - val_loss: 0.0474\n",
            "Epoch 48/100\n",
            "64/64 [==============================] - 9s 134ms/step - loss: 0.0512 - val_loss: 0.0475\n",
            "Epoch 49/100\n",
            "64/64 [==============================] - 9s 143ms/step - loss: 0.0510 - val_loss: 0.0476\n",
            "Epoch 50/100\n",
            "64/64 [==============================] - 9s 139ms/step - loss: 0.0512 - val_loss: 0.0481\n",
            "Epoch 51/100\n",
            "64/64 [==============================] - 9s 135ms/step - loss: 0.0511 - val_loss: 0.0473\n",
            "Epoch 52/100\n",
            "64/64 [==============================] - 9s 134ms/step - loss: 0.0510 - val_loss: 0.0479\n",
            "Epoch 53/100\n",
            "64/64 [==============================] - 9s 135ms/step - loss: 0.0512 - val_loss: 0.0475\n",
            "Epoch 54/100\n",
            "64/64 [==============================] - 9s 134ms/step - loss: 0.0509 - val_loss: 0.0475\n",
            "Epoch 55/100\n",
            "64/64 [==============================] - 9s 133ms/step - loss: 0.0511 - val_loss: 0.0475\n",
            "Epoch 56/100\n",
            "64/64 [==============================] - 9s 135ms/step - loss: 0.0510 - val_loss: 0.0473\n",
            "Epoch 57/100\n",
            "64/64 [==============================] - 9s 135ms/step - loss: 0.0508 - val_loss: 0.0473\n",
            "Epoch 58/100\n",
            "64/64 [==============================] - 9s 136ms/step - loss: 0.0510 - val_loss: 0.0476\n",
            "Epoch 59/100\n",
            "64/64 [==============================] - 9s 135ms/step - loss: 0.0509 - val_loss: 0.0476\n",
            "Epoch 60/100\n",
            "64/64 [==============================] - 9s 136ms/step - loss: 0.0513 - val_loss: 0.0476\n",
            "Epoch 61/100\n",
            "64/64 [==============================] - 9s 134ms/step - loss: 0.0510 - val_loss: 0.0474\n",
            "Epoch 62/100\n",
            "64/64 [==============================] - 9s 134ms/step - loss: 0.0510 - val_loss: 0.0473\n",
            "Epoch 63/100\n",
            "64/64 [==============================] - 9s 135ms/step - loss: 0.0508 - val_loss: 0.0474\n",
            "Epoch 64/100\n",
            "64/64 [==============================] - 9s 134ms/step - loss: 0.0508 - val_loss: 0.0474\n",
            "Epoch 65/100\n",
            "64/64 [==============================] - 9s 136ms/step - loss: 0.0508 - val_loss: 0.0488\n",
            "Epoch 66/100\n",
            "64/64 [==============================] - 9s 136ms/step - loss: 0.0511 - val_loss: 0.0473\n",
            "Epoch 67/100\n",
            "64/64 [==============================] - 9s 134ms/step - loss: 0.0509 - val_loss: 0.0473\n",
            "Epoch 68/100\n",
            "64/64 [==============================] - 9s 133ms/step - loss: 0.0508 - val_loss: 0.0477\n",
            "Epoch 69/100\n",
            "64/64 [==============================] - 9s 135ms/step - loss: 0.0509 - val_loss: 0.0478\n",
            "Epoch 70/100\n",
            "64/64 [==============================] - 9s 134ms/step - loss: 0.0509 - val_loss: 0.0473\n",
            "Epoch 71/100\n",
            "64/64 [==============================] - 9s 134ms/step - loss: 0.0511 - val_loss: 0.0486\n",
            "Epoch 72/100\n",
            "64/64 [==============================] - 8s 133ms/step - loss: 0.0510 - val_loss: 0.0478\n",
            "Epoch 73/100\n",
            "64/64 [==============================] - 9s 139ms/step - loss: 0.0508 - val_loss: 0.0472\n",
            "Epoch 74/100\n",
            "64/64 [==============================] - 9s 135ms/step - loss: 0.0508 - val_loss: 0.0475\n",
            "Epoch 75/100\n",
            "64/64 [==============================] - 9s 137ms/step - loss: 0.0507 - val_loss: 0.0473\n",
            "Epoch 76/100\n",
            "64/64 [==============================] - 9s 138ms/step - loss: 0.0510 - val_loss: 0.0478\n",
            "Epoch 77/100\n",
            "64/64 [==============================] - 9s 137ms/step - loss: 0.0509 - val_loss: 0.0475\n",
            "Epoch 78/100\n",
            "64/64 [==============================] - 9s 138ms/step - loss: 0.0508 - val_loss: 0.0475\n",
            "Epoch 79/100\n",
            "64/64 [==============================] - 9s 137ms/step - loss: 0.0507 - val_loss: 0.0474\n",
            "Epoch 80/100\n",
            "64/64 [==============================] - 9s 137ms/step - loss: 0.0507 - val_loss: 0.0476\n",
            "Epoch 81/100\n",
            "64/64 [==============================] - 9s 138ms/step - loss: 0.0505 - val_loss: 0.0476\n",
            "Epoch 82/100\n",
            "64/64 [==============================] - 9s 139ms/step - loss: 0.0508 - val_loss: 0.0474\n",
            "Epoch 83/100\n",
            "64/64 [==============================] - 9s 138ms/step - loss: 0.0507 - val_loss: 0.0473\n",
            "Epoch 84/100\n",
            "64/64 [==============================] - 9s 144ms/step - loss: 0.0509 - val_loss: 0.0474\n",
            "Epoch 85/100\n",
            "64/64 [==============================] - 9s 143ms/step - loss: 0.0508 - val_loss: 0.0472\n",
            "Epoch 86/100\n",
            "64/64 [==============================] - 9s 135ms/step - loss: 0.0510 - val_loss: 0.0473\n",
            "Epoch 87/100\n",
            "64/64 [==============================] - 9s 136ms/step - loss: 0.0506 - val_loss: 0.0475\n",
            "Epoch 88/100\n",
            "64/64 [==============================] - 9s 135ms/step - loss: 0.0510 - val_loss: 0.0477\n",
            "Epoch 89/100\n",
            "64/64 [==============================] - 9s 135ms/step - loss: 0.0511 - val_loss: 0.0475\n",
            "Epoch 90/100\n",
            "64/64 [==============================] - 9s 136ms/step - loss: 0.0508 - val_loss: 0.0476\n",
            "Epoch 91/100\n",
            "64/64 [==============================] - 9s 136ms/step - loss: 0.0508 - val_loss: 0.0477\n",
            "Epoch 92/100\n",
            "64/64 [==============================] - 9s 136ms/step - loss: 0.0508 - val_loss: 0.0477\n",
            "Epoch 93/100\n",
            "64/64 [==============================] - 9s 136ms/step - loss: 0.0509 - val_loss: 0.0477\n",
            "Epoch 94/100\n",
            "64/64 [==============================] - 9s 136ms/step - loss: 0.0507 - val_loss: 0.0473\n",
            "Epoch 95/100\n",
            "64/64 [==============================] - 9s 135ms/step - loss: 0.0505 - val_loss: 0.0475\n",
            "Epoch 96/100\n",
            "64/64 [==============================] - 9s 134ms/step - loss: 0.0507 - val_loss: 0.0474\n",
            "Epoch 97/100\n",
            "64/64 [==============================] - 9s 133ms/step - loss: 0.0506 - val_loss: 0.0476\n",
            "Epoch 98/100\n",
            "64/64 [==============================] - 9s 135ms/step - loss: 0.0508 - val_loss: 0.0475\n",
            "Epoch 99/100\n",
            "64/64 [==============================] - 9s 135ms/step - loss: 0.0508 - val_loss: 0.0477\n",
            "Epoch 100/100\n",
            "64/64 [==============================] - 9s 135ms/step - loss: 0.0506 - val_loss: 0.0476\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyhvljWYYyKg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "02baad31-e840-4639-d375-5e52d7c6f44d"
      },
      "source": [
        "# SimpleRNN 네트워크 학습 결과 확인\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['loss'], 'b-', label='loss')\n",
        "plt.plot(history.history['val_loss'], 'b-', label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-fdccb0485fa4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# SimpleRNN 네트워크 학습 결과 확인\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'b-'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'b-'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5r8VgzGYZM-L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "f028688b-334a-4789-9fc4-1d4bd8071c22"
      },
      "source": [
        "# 테스트 데이터에 대한 예측 정확도 확인\n",
        "model.evaluate(X[2560:], Y[2560:])\n",
        "prediction = model.predict(X[2560:2560+5])\n",
        "\n",
        "# 5개 테스트 데이터에 대한 예측을 표시한다.\n",
        "for i in range(5):\n",
        "  print(Y[2560+i], '\\t'), prediction[i][0], '\\tdiff:', abs(prediction[i][0] - Y[2560+i])\n",
        "\n",
        "prediction = model.predict(X[2560:])\n",
        "fail = 0\n",
        "for i in range(len(prediction)):\n",
        "  # 오차가 0.4 이상이면 오답이다.\n",
        "  if abs(prediction[i][0] - Y[2560+i]) > 0.04:\n",
        "    fail +=1\n",
        "print('correnctness:', (440 - fail) / 440 * 100, '%')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14/14 [==============================] - 0s 16ms/step - loss: 0.0545\n",
            "0.16001983160241762 \t\n",
            "0.15214741989955927 \t\n",
            "0.11939323465419154 \t\n",
            "0.21953766860824392 \t\n",
            "0.6947271192171183 \t\n",
            "correnctness: 9.545454545454547 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_ByTbE3a1mP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "00acac3f-47b6-4e11-8664-13ef95b43c33"
      },
      "source": [
        "# LSTM 레이어를 이용한 곱셈 문제 모델 정의\n",
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.LSTM(units=30, return_sequences=True, input_shape=[100,2]),\n",
        "  tf.keras.layers.LSTM(units=30),\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "model.summary()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 100, 30)           3960      \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 30)                7320      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 31        \n",
            "=================================================================\n",
            "Total params: 11,311\n",
            "Trainable params: 11,311\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VsN8iM2b5PK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# LSTM 네트워크 학습\n",
        "X = np.array(X)\n",
        "Y = np.array(Y)\n",
        "history = model.fit(X[:2560], Y[:2560], epochs=100, validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUqkHTFycMMb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "2e249d2b-631b-45f7-cd61-e539f0744fe0"
      },
      "source": [
        "# LSTM 네트워크의 학습 결과 확인\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['loss'], 'b-', label='loss')\n",
        "plt.plot(history.history['val_loss'], 'b-', label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDS4nTyTceJo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "403cb492-ca74-4155-f7d0-201b94ad94ba"
      },
      "source": [
        "# 테스트 데이터에 대한 예측 정확도 확인\n",
        "model.evaluate(X[2560:], Y[2560:])\n",
        "prediction = model.predict(X[2560:2560+5])\n",
        "\n",
        "# 5개 테스트 데이터에 대한 예측을 표시한다.\n",
        "for i in range(5):\n",
        "  print(Y[2560+i], '\\t'), prediction[i][0], '\\tdiff:', abs(prediction[i][0] - Y[2560+i])\n",
        "\n",
        "prediction = model.predict(X[2560:])\n",
        "cnt = 0\n",
        "for i in range(len(prediction)):\n",
        "  if abs(prediction[i][0] - Y[2560+i]) > 0.04:\n",
        "    cnt +=1\n",
        "print('correnctness:', (440 - cnt) / 440 * 100, '%')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14/14 [==============================] - 0s 13ms/step - loss: 5.0716e-04\n",
            "0.16001983160241762 \t\n",
            "0.15214741989955927 \t\n",
            "0.11939323465419154 \t\n",
            "0.21953766860824392 \t\n",
            "0.6947271192171183 \t\n",
            "correnctness: 93.63636363636364 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GcOeRkOdKl1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "5f20b93c-ac3b-44e7-939f-bcf2f48b8efb"
      },
      "source": [
        "# GRU 레이어를 이용한 곱셈 문제 모델 정의\n",
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.GRU(units=30, return_sequences=True, input_shape=[100,2]),\n",
        "  tf.keras.layers.GRU(units=30),\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "model.summary()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru (GRU)                    (None, 100, 30)           3060      \n",
            "_________________________________________________________________\n",
            "gru_1 (GRU)                  (None, 30)                5580      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 31        \n",
            "=================================================================\n",
            "Total params: 8,671\n",
            "Trainable params: 8,671\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBo4LQj3d8CY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c8e0d50f-4c1b-4317-ceb8-02caee29be75"
      },
      "source": [
        "# GRU 레이어 네트워크 학습\n",
        "X = np.array(X)\n",
        "Y = np.array(Y)\n",
        "history = model.fit(X[:2560], Y[:2560], epochs=100, validation_split=0.2)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            " 1/64 [..............................] - ETA: 0s - loss: 0.0853WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0114s vs `on_train_batch_end` time: 0.0255s). Check your callbacks.\n",
            "63/64 [============================>.] - ETA: 0s - loss: 0.0530WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0046s vs `on_test_batch_end` time: 0.0077s). Check your callbacks.\n",
            "64/64 [==============================] - 3s 53ms/step - loss: 0.0529 - val_loss: 0.0504\n",
            "Epoch 2/100\n",
            "64/64 [==============================] - 3s 45ms/step - loss: 0.0507 - val_loss: 0.0501\n",
            "Epoch 3/100\n",
            "64/64 [==============================] - 3s 45ms/step - loss: 0.0501 - val_loss: 0.0501\n",
            "Epoch 4/100\n",
            "64/64 [==============================] - 3s 44ms/step - loss: 0.0505 - val_loss: 0.0504\n",
            "Epoch 5/100\n",
            "64/64 [==============================] - 3s 44ms/step - loss: 0.0498 - val_loss: 0.0501\n",
            "Epoch 6/100\n",
            "64/64 [==============================] - 3s 45ms/step - loss: 0.0498 - val_loss: 0.0504\n",
            "Epoch 7/100\n",
            "64/64 [==============================] - 3s 44ms/step - loss: 0.0498 - val_loss: 0.0513\n",
            "Epoch 8/100\n",
            "64/64 [==============================] - 3s 43ms/step - loss: 0.0496 - val_loss: 0.0502\n",
            "Epoch 9/100\n",
            "64/64 [==============================] - 3s 45ms/step - loss: 0.0496 - val_loss: 0.0501\n",
            "Epoch 10/100\n",
            "64/64 [==============================] - 3s 44ms/step - loss: 0.0494 - val_loss: 0.0506\n",
            "Epoch 11/100\n",
            "64/64 [==============================] - 3s 44ms/step - loss: 0.0494 - val_loss: 0.0502\n",
            "Epoch 12/100\n",
            "64/64 [==============================] - 3s 44ms/step - loss: 0.0491 - val_loss: 0.0501\n",
            "Epoch 13/100\n",
            "64/64 [==============================] - 3s 44ms/step - loss: 0.0492 - val_loss: 0.0500\n",
            "Epoch 14/100\n",
            "64/64 [==============================] - 3s 44ms/step - loss: 0.0491 - val_loss: 0.0500\n",
            "Epoch 15/100\n",
            "64/64 [==============================] - 3s 43ms/step - loss: 0.0486 - val_loss: 0.0499\n",
            "Epoch 16/100\n",
            "64/64 [==============================] - 3s 44ms/step - loss: 0.0481 - val_loss: 0.0499\n",
            "Epoch 17/100\n",
            "64/64 [==============================] - 3s 44ms/step - loss: 0.0484 - val_loss: 0.0498\n",
            "Epoch 18/100\n",
            "64/64 [==============================] - 3s 44ms/step - loss: 0.0484 - val_loss: 0.0485\n",
            "Epoch 19/100\n",
            "64/64 [==============================] - 3s 44ms/step - loss: 0.0476 - val_loss: 0.0477\n",
            "Epoch 20/100\n",
            "64/64 [==============================] - 3s 44ms/step - loss: 0.0477 - val_loss: 0.0473\n",
            "Epoch 21/100\n",
            "64/64 [==============================] - 3s 44ms/step - loss: 0.0464 - val_loss: 0.0474\n",
            "Epoch 22/100\n",
            "64/64 [==============================] - 3s 44ms/step - loss: 0.0414 - val_loss: 0.0163\n",
            "Epoch 23/100\n",
            "64/64 [==============================] - 3s 44ms/step - loss: 0.0096 - val_loss: 0.0055\n",
            "Epoch 24/100\n",
            "64/64 [==============================] - 3s 44ms/step - loss: 0.0035 - val_loss: 0.0033\n",
            "Epoch 25/100\n",
            "64/64 [==============================] - 3s 44ms/step - loss: 0.0024 - val_loss: 0.0043\n",
            "Epoch 26/100\n",
            "64/64 [==============================] - 3s 45ms/step - loss: 0.0021 - val_loss: 0.0018\n",
            "Epoch 27/100\n",
            "64/64 [==============================] - 3s 44ms/step - loss: 0.0016 - val_loss: 0.0018\n",
            "Epoch 28/100\n",
            "64/64 [==============================] - 3s 44ms/step - loss: 0.0019 - val_loss: 0.0015\n",
            "Epoch 29/100\n",
            "64/64 [==============================] - 3s 44ms/step - loss: 0.0013 - val_loss: 0.0014\n",
            "Epoch 30/100\n",
            "64/64 [==============================] - 3s 44ms/step - loss: 0.0012 - val_loss: 0.0013\n",
            "Epoch 31/100\n",
            "64/64 [==============================] - 3s 44ms/step - loss: 0.0013 - val_loss: 0.0014\n",
            "Epoch 32/100\n",
            "64/64 [==============================] - 3s 44ms/step - loss: 0.0012 - val_loss: 0.0012\n",
            "Epoch 33/100\n",
            "64/64 [==============================] - 3s 44ms/step - loss: 0.0010 - val_loss: 0.0010\n",
            "Epoch 34/100\n",
            "64/64 [==============================] - 3s 44ms/step - loss: 0.0011 - val_loss: 0.0012\n",
            "Epoch 35/100\n",
            "64/64 [==============================] - 3s 44ms/step - loss: 9.3973e-04 - val_loss: 9.7331e-04\n",
            "Epoch 36/100\n",
            "64/64 [==============================] - 3s 43ms/step - loss: 7.4817e-04 - val_loss: 9.4290e-04\n",
            "Epoch 37/100\n",
            "64/64 [==============================] - 3s 44ms/step - loss: 9.3550e-04 - val_loss: 9.3303e-04\n",
            "Epoch 38/100\n",
            "64/64 [==============================] - 3s 44ms/step - loss: 7.5121e-04 - val_loss: 8.8463e-04\n",
            "Epoch 39/100\n",
            "64/64 [==============================] - 3s 44ms/step - loss: 6.9546e-04 - val_loss: 8.2104e-04\n",
            "Epoch 40/100\n",
            "64/64 [==============================] - 3s 43ms/step - loss: 6.1716e-04 - val_loss: 7.1082e-04\n",
            "Epoch 41/100\n",
            "64/64 [==============================] - 3s 43ms/step - loss: 6.2604e-04 - val_loss: 9.4563e-04\n",
            "Epoch 42/100\n",
            "64/64 [==============================] - 3s 44ms/step - loss: 6.8222e-04 - val_loss: 0.0011\n",
            "Epoch 43/100\n",
            "64/64 [==============================] - 3s 43ms/step - loss: 6.6626e-04 - val_loss: 6.8160e-04\n",
            "Epoch 44/100\n",
            "64/64 [==============================] - 3s 44ms/step - loss: 6.4262e-04 - val_loss: 0.0014\n",
            "Epoch 45/100\n",
            "64/64 [==============================] - 3s 43ms/step - loss: 5.9969e-04 - val_loss: 6.4710e-04\n",
            "Epoch 46/100\n",
            "64/64 [==============================] - 3s 44ms/step - loss: 4.9852e-04 - val_loss: 6.7171e-04\n",
            "Epoch 47/100\n",
            "64/64 [==============================] - 3s 44ms/step - loss: 5.4747e-04 - val_loss: 7.1852e-04\n",
            "Epoch 48/100\n",
            "64/64 [==============================] - 3s 44ms/step - loss: 6.1698e-04 - val_loss: 5.7526e-04\n",
            "Epoch 49/100\n",
            "64/64 [==============================] - 3s 44ms/step - loss: 5.0723e-04 - val_loss: 6.0038e-04\n",
            "Epoch 50/100\n",
            "64/64 [==============================] - 3s 44ms/step - loss: 4.9453e-04 - val_loss: 6.7483e-04\n",
            "Epoch 51/100\n",
            "64/64 [==============================] - 3s 44ms/step - loss: 4.6365e-04 - val_loss: 6.8490e-04\n",
            "Epoch 52/100\n",
            "64/64 [==============================] - 3s 44ms/step - loss: 4.5977e-04 - val_loss: 5.6744e-04\n",
            "Epoch 53/100\n",
            "64/64 [==============================] - 3s 43ms/step - loss: 4.1277e-04 - val_loss: 5.3048e-04\n",
            "Epoch 54/100\n",
            "64/64 [==============================] - 3s 44ms/step - loss: 3.9002e-04 - val_loss: 5.4893e-04\n",
            "Epoch 55/100\n",
            "64/64 [==============================] - 3s 44ms/step - loss: 6.1381e-04 - val_loss: 5.9345e-04\n",
            "Epoch 56/100\n",
            "64/64 [==============================] - 3s 44ms/step - loss: 5.9793e-04 - val_loss: 5.7876e-04\n",
            "Epoch 57/100\n",
            "64/64 [==============================] - 3s 44ms/step - loss: 3.6266e-04 - val_loss: 4.9494e-04\n",
            "Epoch 58/100\n",
            "64/64 [==============================] - 3s 44ms/step - loss: 3.7868e-04 - val_loss: 4.5704e-04\n",
            "Epoch 59/100\n",
            "64/64 [==============================] - 3s 45ms/step - loss: 3.9158e-04 - val_loss: 5.4062e-04\n",
            "Epoch 60/100\n",
            "64/64 [==============================] - 3s 44ms/step - loss: 3.3827e-04 - val_loss: 4.7537e-04\n",
            "Epoch 61/100\n",
            "64/64 [==============================] - 3s 44ms/step - loss: 3.9887e-04 - val_loss: 5.5656e-04\n",
            "Epoch 62/100\n",
            "64/64 [==============================] - 3s 44ms/step - loss: 3.2262e-04 - val_loss: 4.6783e-04\n",
            "Epoch 63/100\n",
            "64/64 [==============================] - 3s 44ms/step - loss: 3.1864e-04 - val_loss: 4.1222e-04\n",
            "Epoch 64/100\n",
            "64/64 [==============================] - 3s 44ms/step - loss: 3.2054e-04 - val_loss: 5.0157e-04\n",
            "Epoch 65/100\n",
            "64/64 [==============================] - 3s 44ms/step - loss: 3.8211e-04 - val_loss: 5.9433e-04\n",
            "Epoch 66/100\n",
            "64/64 [==============================] - 3s 44ms/step - loss: 2.7501e-04 - val_loss: 3.2397e-04\n",
            "Epoch 67/100\n",
            "64/64 [==============================] - 3s 44ms/step - loss: 2.8858e-04 - val_loss: 3.4762e-04\n",
            "Epoch 68/100\n",
            "64/64 [==============================] - 3s 43ms/step - loss: 3.8053e-04 - val_loss: 7.9902e-04\n",
            "Epoch 69/100\n",
            "64/64 [==============================] - 3s 44ms/step - loss: 3.6969e-04 - val_loss: 3.7031e-04\n",
            "Epoch 70/100\n",
            "64/64 [==============================] - 3s 44ms/step - loss: 2.6455e-04 - val_loss: 3.4734e-04\n",
            "Epoch 71/100\n",
            "64/64 [==============================] - 3s 44ms/step - loss: 3.0534e-04 - val_loss: 5.8137e-04\n",
            "Epoch 72/100\n",
            "64/64 [==============================] - 3s 44ms/step - loss: 3.2141e-04 - val_loss: 3.2793e-04\n",
            "Epoch 73/100\n",
            "64/64 [==============================] - 3s 43ms/step - loss: 2.6848e-04 - val_loss: 3.4205e-04\n",
            "Epoch 74/100\n",
            "64/64 [==============================] - 3s 44ms/step - loss: 3.3884e-04 - val_loss: 2.8948e-04\n",
            "Epoch 75/100\n",
            "64/64 [==============================] - 3s 44ms/step - loss: 3.0901e-04 - val_loss: 3.4315e-04\n",
            "Epoch 76/100\n",
            "64/64 [==============================] - 3s 44ms/step - loss: 2.7035e-04 - val_loss: 3.5108e-04\n",
            "Epoch 77/100\n",
            "64/64 [==============================] - 3s 44ms/step - loss: 2.4154e-04 - val_loss: 4.2042e-04\n",
            "Epoch 78/100\n",
            "64/64 [==============================] - 3s 45ms/step - loss: 2.1272e-04 - val_loss: 3.5917e-04\n",
            "Epoch 79/100\n",
            "64/64 [==============================] - 3s 43ms/step - loss: 2.8693e-04 - val_loss: 8.1013e-04\n",
            "Epoch 80/100\n",
            "64/64 [==============================] - 3s 44ms/step - loss: 2.8947e-04 - val_loss: 3.4965e-04\n",
            "Epoch 81/100\n",
            "64/64 [==============================] - 3s 44ms/step - loss: 2.4959e-04 - val_loss: 2.8911e-04\n",
            "Epoch 82/100\n",
            "64/64 [==============================] - 3s 44ms/step - loss: 3.0824e-04 - val_loss: 2.4028e-04\n",
            "Epoch 83/100\n",
            "64/64 [==============================] - 3s 44ms/step - loss: 2.7121e-04 - val_loss: 2.8012e-04\n",
            "Epoch 84/100\n",
            "64/64 [==============================] - 3s 44ms/step - loss: 2.1717e-04 - val_loss: 4.3514e-04\n",
            "Epoch 85/100\n",
            "64/64 [==============================] - 3s 44ms/step - loss: 2.8675e-04 - val_loss: 2.4261e-04\n",
            "Epoch 86/100\n",
            "64/64 [==============================] - 3s 44ms/step - loss: 2.1515e-04 - val_loss: 4.9139e-04\n",
            "Epoch 87/100\n",
            "64/64 [==============================] - 3s 44ms/step - loss: 5.0725e-04 - val_loss: 8.0266e-04\n",
            "Epoch 88/100\n",
            "64/64 [==============================] - 3s 44ms/step - loss: 3.1416e-04 - val_loss: 2.1895e-04\n",
            "Epoch 89/100\n",
            "64/64 [==============================] - 3s 44ms/step - loss: 1.8715e-04 - val_loss: 2.5970e-04\n",
            "Epoch 90/100\n",
            "64/64 [==============================] - 3s 44ms/step - loss: 2.3026e-04 - val_loss: 2.9510e-04\n",
            "Epoch 91/100\n",
            "64/64 [==============================] - 3s 44ms/step - loss: 1.8266e-04 - val_loss: 3.0362e-04\n",
            "Epoch 92/100\n",
            "64/64 [==============================] - 3s 44ms/step - loss: 1.9245e-04 - val_loss: 2.1681e-04\n",
            "Epoch 93/100\n",
            "64/64 [==============================] - 3s 44ms/step - loss: 1.9516e-04 - val_loss: 2.5730e-04\n",
            "Epoch 94/100\n",
            "64/64 [==============================] - 3s 43ms/step - loss: 2.0090e-04 - val_loss: 3.2309e-04\n",
            "Epoch 95/100\n",
            "64/64 [==============================] - 3s 44ms/step - loss: 2.7672e-04 - val_loss: 2.9298e-04\n",
            "Epoch 96/100\n",
            "64/64 [==============================] - 3s 44ms/step - loss: 1.7181e-04 - val_loss: 2.3368e-04\n",
            "Epoch 97/100\n",
            "64/64 [==============================] - 3s 44ms/step - loss: 1.6040e-04 - val_loss: 5.5633e-04\n",
            "Epoch 98/100\n",
            "64/64 [==============================] - 3s 45ms/step - loss: 1.9752e-04 - val_loss: 2.0095e-04\n",
            "Epoch 99/100\n",
            "64/64 [==============================] - 3s 44ms/step - loss: 2.4800e-04 - val_loss: 3.1529e-04\n",
            "Epoch 100/100\n",
            "64/64 [==============================] - 3s 44ms/step - loss: 1.6328e-04 - val_loss: 2.4393e-04\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGTGeKudd_uM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "f4efc98f-8d03-411e-80b6-c81d01cdc35b"
      },
      "source": [
        "# GRU 레이어 네트워크의 학습 결과 확인\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['loss'], 'b-', label='loss')\n",
        "plt.plot(history.history['val_loss'], 'b-', label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JQJPJLueEAN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "0b155db7-b4d9-42a4-b017-54eccb41a28c"
      },
      "source": [
        "# 테스트 데이터에 대한 예측 정확도 확인\n",
        "model.evaluate(X[2560:], Y[2560:])\n",
        "prediction = model.predict(X[2560:2560+5])\n",
        "\n",
        "# 5개 테스트 데이터에 대한 예측을 표시한다.\n",
        "for i in range(5):\n",
        "  print(Y[2560+i], '\\t'), prediction[i][0], '\\tdiff:', abs(prediction[i][0] - Y[2560+i])\n",
        "\n",
        "prediction = model.predict(X[2560:])\n",
        "cnt = 0\n",
        "for i in range(len(prediction)):\n",
        "  if abs(prediction[i][0] - Y[2560+i]) > 0.04:\n",
        "    cnt +=1\n",
        "print('correnctness:', (440 - cnt) / 440 * 100, '%')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14/14 [==============================] - 0s 13ms/step - loss: 2.4414e-04\n",
            "0.16001983160241762 \t\n",
            "0.15214741989955927 \t\n",
            "0.11939323465419154 \t\n",
            "0.21953766860824392 \t\n",
            "0.6947271192171183 \t\n",
            "correnctness: 97.72727272727273 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anDwWkzTgYnf",
        "colab_type": "text"
      },
      "source": [
        "# 임베딩 레이어\n",
        "영화 리뷰를 통해서 긍정 부정을 판단해보자"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-ie8iAagg8k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4e2e5f98-af62-4baf-8237-13ef96b71203"
      },
      "source": [
        "# Naver Sentiment Movie Corpus v1.0 다운로드\n",
        "path_to_train_file = tf.keras.utils.get_file('train.txt', 'https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt')\n",
        "path_to_test_file = tf.keras.utils.get_file('test.txt', 'https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt\n",
            "4898816/4893335 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4a-5dqBhPB7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "82213092-b2ce-484d-a70f-f6117854044f"
      },
      "source": [
        "# 데이터 로드 및 확인\n",
        "# 데이터를 메모리에 불러온다. 인코딩 형식으로 utf-8을 지정한다.\n",
        "train_text = open(path_to_train_file, 'rb').read().decode(encoding='utf-8')\n",
        "test_text = open(path_to_test_file, 'rb').read().decode(encoding='utf-8')\n",
        "\n",
        "# 텍스트가 총 몇 자인지 확인한다.\n",
        "print('Lenfth of text : {} charaters'.format(len(train_text)))\n",
        "print('Lenfth of text : {} charaters'.format(len(test_text)))\n",
        "\n",
        "# 처음 300자를 확인한다\n",
        "print(train_text[:300])\n",
        "print(test_text[:300])"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Lenfth of text : 6937271 charaters\n",
            "Lenfth of text : 2318260 charaters\n",
            "id\tdocument\tlabel\n",
            "9976970\t아 더빙.. 진짜 짜증나네요 목소리\t0\n",
            "3819312\t흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나\t1\n",
            "10265843\t너무재밓었다그래서보는것을추천한다\t0\n",
            "9045019\t교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정\t0\n",
            "6483659\t사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 던스트가 너무나도 이뻐보였다\t1\n",
            "5403919\t막 걸음마 뗀 3세부터 초등학교 1학년생인 8살용영화.ㅋㅋㅋ...별반개도 아까움.\t0\n",
            "7797314\t원작의\n",
            "id\tdocument\tlabel\n",
            "6270596\t굳 ㅋ\t1\n",
            "9274899\tGDNTOPCLASSINTHECLUB\t0\n",
            "8544678\t뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아\t0\n",
            "6825595\t지루하지는 않은데 완전 막장임... 돈주고 보기에는....\t0\n",
            "6723715\t3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??\t0\n",
            "7898805\t음악이 주가 된, 최고의 음악영화\t1\n",
            "6315043\t진정한 쓰레기\t0\n",
            "6097171\t마치 미국애니에서 튀어나온듯한 창의력없는 로봇디자인부터\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66uJBXsmiATk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "4a7840bd-b70e-4a8b-b2b2-457856fb50cd"
      },
      "source": [
        "# 학습을 위한 정답 데이터(Y) 만들기\n",
        "train_Y = np.array([[int(row.split('\\t')[2])] for row in train_text.split('\\n')[1:] if row.count('\\t') > 0])\n",
        "test_Y = np.array([[int(row.split('\\t')[2])] for row in test_text.split('\\n')[1:] if row.count('\\t') > 0])\n",
        "\n",
        "print(train_Y.shape, test_Y.shape)\n",
        "print(train_Y)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(150000, 1) (50000, 1)\n",
            "[[1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPvLO3UpjX7v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "e64ee00f-f9bf-4629-dfe3-cb98751d8d4b"
      },
      "source": [
        "# 훈련 데이터의 입력(X) 정제\n",
        "import re\n",
        "\n",
        "def clean_str(string):\n",
        "  string = re.sub(r\"[^가-힣A-Za-z0-9(),!?\\'\\`]\", \" \", string)\n",
        "  string = re.sub(r\"\\'s\", \" \\'s\", string)\n",
        "  string = re.sub(r\"\\'ve\", \" \\'ve\", string)\n",
        "  string = re.sub(r\"n\\'t\", \" n\\'t\" , string)\n",
        "  string = re.sub(r\"\\'re\", \" \\'re\" , string)\n",
        "  string = re.sub(r\"\\'d\", \" \\'d\" , string)\n",
        "  string = re.sub(r\"\\'ll\", \" \\'ll\" , string)\n",
        "  string = re.sub(r\",\", \" , \" , string)\n",
        "  string = re.sub(r\"!\", \" ! \" , string)\n",
        "  string = re.sub(r\"\\(\", \" \\( \" , string)\n",
        "  string = re.sub(r\"\\)\", \" \\) \" , string)\n",
        "  string = re.sub(r\"\\?\", \" \\? \" , string)\n",
        "  string = re.sub(r\"\\s{2,}\", \" \" , string)\n",
        "  string = re.sub(r\"\\'{2,}\", \"\\'\" , string)\n",
        "  string = re.sub(r\"\\'\", \"\" , string)\n",
        "\n",
        "  return string.lower()\n",
        "\n",
        "train_text_X = [row.split('\\t')[1] for row in train_text.split('\\n')[1:] if row.count('\\t') > 0]\n",
        "test_text_X = [clean_str(sentence) for sentence in train_text_X]\n",
        "\n",
        "sentences = [sentence.split(' ') for sentence in train_text_X]\n",
        "for i in range(5):\n",
        "  print(sentences[i])"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['아', '더빙..', '진짜', '짜증나네요', '목소리']\n",
            "['흠...포스터보고', '초딩영화줄....오버연기조차', '가볍지', '않구나']\n",
            "['너무재밓었다그래서보는것을추천한다']\n",
            "['교도소', '이야기구먼', '..솔직히', '재미는', '없다..평점', '조정']\n",
            "['사이몬페그의', '익살스런', '연기가', '돋보였던', '영화!스파이더맨에서', '늙어보이기만', '했던', '커스틴', '던스트가', '너무나도', '이뻐보였다']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxOvb1wwlPR2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "c62be2db-baf8-49b5-9547-6ebf6704ba42"
      },
      "source": [
        "# 각 문장의 단어 길이 확인\n",
        "import matplotlib.pyplot as plt\n",
        "sentence_len = [len(sentence) for sentence in sentences]\n",
        "sentence_len.sort()\n",
        "plt.plot(sentence_len)\n",
        "plt.show()\n",
        "\n",
        "print(sum([int(l<=25) for l in sentence_len]))"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "144646\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujgIczp2l7lr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "2d3c7c55-75cc-41c1-ea1d-93cd61306880"
      },
      "source": [
        "# 단어 정제 및 문장 길이 줄임\n",
        "sentence_new = []\n",
        "for sentence in sentences:\n",
        "  sentence_new.append([word[:5] for word in sentence][:25])\n",
        "sentences = sentence_new\n",
        "for i in range(5):\n",
        "  print(sentences[i])"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['아', '더빙..', '진짜', '짜증나네요', '목소리']\n",
            "['흠...포', '초딩영화줄', '가볍지', '않구나']\n",
            "['너무재밓었']\n",
            "['교도소', '이야기구먼', '..솔직히', '재미는', '없다..평', '조정']\n",
            "['사이몬페그', '익살스런', '연기가', '돋보였던', '영화!스파', '늙어보이기', '했던', '커스틴', '던스트가', '너무나도', '이뻐보였다']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qi36M3VYmiMC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "3ea64f23-7fdd-4498-a917-269982df3dcc"
      },
      "source": [
        "# Tokenizer와 pad_sequences를 이용한 문장 전처리\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "tokenizer = Tokenizer(num_words=20000)\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "train_X = tokenizer.texts_to_sequences(sentences)\n",
        "train_X = pad_sequences(train_X, padding='post')\n",
        "\n",
        "print(train_X[:5])"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[   49     4  6717  1068     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0]\n",
            " [ 6718     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0]\n",
            " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0]\n",
            " [  324 11089     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0]\n",
            " [   95  5218   787   501     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGw_DLAtnmYg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "df15ae54-ada1-4a2d-f0fc-f9f17b4073ed"
      },
      "source": [
        "# 감성 분석을 위한 모델 정의\n",
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Embedding(20000, 300, input_length=25),\n",
        "  tf.keras.layers.LSTM(units=50),\n",
        "  tf.keras.layers.Dense(2, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 25, 300)           6000000   \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 50)                70200     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 2)                 102       \n",
            "=================================================================\n",
            "Total params: 6,070,302\n",
            "Trainable params: 6,070,302\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ghtP1ppoWo1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "dbe1bf4e-b498-4a17-ebb8-5dd6080c7778"
      },
      "source": [
        "# 감성 분석 모델 학습\n",
        "history = model.fit(train_X, train_Y, epochs=5, batch_size=128, validation_split=0.2)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "938/938 [==============================] - 73s 78ms/step - loss: 0.4679 - accuracy: 0.7559 - val_loss: 0.4080 - val_accuracy: 0.7984\n",
            "Epoch 2/5\n",
            "938/938 [==============================] - 75s 80ms/step - loss: 0.3559 - accuracy: 0.8226 - val_loss: 0.4116 - val_accuracy: 0.7980\n",
            "Epoch 3/5\n",
            "938/938 [==============================] - 75s 79ms/step - loss: 0.3003 - accuracy: 0.8459 - val_loss: 0.4621 - val_accuracy: 0.7913\n",
            "Epoch 4/5\n",
            "938/938 [==============================] - 74s 79ms/step - loss: 0.2547 - accuracy: 0.8672 - val_loss: 0.5380 - val_accuracy: 0.7859\n",
            "Epoch 5/5\n",
            "938/938 [==============================] - 74s 78ms/step - loss: 0.2209 - accuracy: 0.8830 - val_loss: 0.6057 - val_accuracy: 0.7741\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfLh9QZaopZ6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "outputId": "2871b3ab-154b-4d88-f77a-356f126dcc0a"
      },
      "source": [
        "# 감성 분석 모델 학습 결과 확인\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(12,4))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(history.history['loss'], 'b-', label='loss')\n",
        "plt.plot(history.history['val_loss'], 'r--', label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(history.history['accuracy'], 'b-', label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], 'k--', label='val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylim(0.7,1)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-0b4c179715d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'b-'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r--'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAAD8CAYAAADUv3dIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAANIklEQVR4nO3cYajd9X3H8fdHs6zM2TqWWyhJWi2Ls8ENdBfnKKwO3Yg+SB50lASk6wiGdrMMWgYOhyv2UVfWQSFbmzFxLVRr+6BcaEqgnSJI47yitSZiuU1dTSrz1jqfSNWw7x6c4zi9Jt5/47nfu3vyfsGF8/+f3z3n+8+5952Tc84/qSokST0uWO8BJOl8YnQlqZHRlaRGRleSGhldSWpkdCWp0arRTXJXkueTPHmW65Pk80mWkjyR5OrpjylJs2HIM927gV1vcv2NwI7x1wHgn9/6WJI0m1aNblU9CPzsTZbsAb5UI0eBS5K8a1oDStIs2TSF29gKPDuxfXK877mVC5McYPRsmIsuuuj3rrjiiincvST1evTRR39aVXPn8r3TiO5gVXUIOAQwPz9fi4uLnXcvSVOR5D/P9Xun8emFU8D2ie1t432SpBWmEd0F4MPjTzFcC7xUVW94aUGSNODlhST3ANcBW5KcBP4O+BWAqvoCcBi4CVgCXgb+fK2GlaSNbtXoVtW+Va4v4C+nNpEkzTDPSJOkRkZXkhoZXUlqZHQlqZHRlaRGRleSGhldSWpkdCWpkdGVpEZGV5IaGV1JamR0JamR0ZWkRkZXkhoZXUlqZHQlqZHRlaRGRleSGhldSWpkdCWpkdGVpEZGV5IaGV1JamR0JamR0ZWkRkZXkhoZXUlqZHQlqZHRlaRGRleSGhldSWpkdCWpkdGVpEZGV5IaGV1JajQoukl2JXk6yVKS285w/buT3J/ksSRPJLlp+qNK0sa3anSTXAgcBG4EdgL7kuxcsexvgfuq6ipgL/BP0x5UkmbBkGe61wBLVXWiql4F7gX2rFhTwNvHl98B/GR6I0rS7BgS3a3AsxPbJ8f7Jn0KuDnJSeAw8PEz3VCSA0kWkywuLy+fw7iStLFN6420fcDdVbUNuAn4cpI33HZVHaqq+aqan5ubm9JdS9LGMSS6p4DtE9vbxvsm7QfuA6iq7wJvA7ZMY0BJmiVDovsIsCPJZUk2M3qjbGHFmh8D1wMkeR+j6Pr6gSStsGp0q+o0cCtwBHiK0acUjiW5M8nu8bJPArck+R5wD/CRqqq1GlqSNqpNQxZV1WFGb5BN7rtj4vJx4P3THU2SZo9npElSI6MrSY2MriQ1MrqS1MjoSlIjoytJjYyuJDUyupLUyOhKUiOjK0mNjK4kNTK6ktTI6EpSI6MrSY2MriQ1MrqS1MjoSlIjoytJjYyuJDUyupLUyOhKUiOjK0mNjK4kNTK6ktTI6EpSI6MrSY2MriQ1MrqS1MjoSlIjoytJjYyuJDUyupLUyOhKUiOjK0mNBkU3ya4kTydZSnLbWdZ8KMnxJMeSfGW6Y0rSbNi02oIkFwIHgT8GTgKPJFmoquMTa3YAfwO8v6peTPLOtRpYkjayIc90rwGWqupEVb0K3AvsWbHmFuBgVb0IUFXPT3dMSZoNQ6K7FXh2YvvkeN+ky4HLkzyU5GiSXWe6oSQHkiwmWVxeXj63iSVpA5vWG2mbgB3AdcA+4F+SXLJyUVUdqqr5qpqfm5ub0l1L0sYxJLqngO0T29vG+yadBBaq6rWq+hHwA0YRliRNGBLdR4AdSS5LshnYCyysWPMNRs9ySbKF0csNJ6Y4pyTNhFWjW1WngVuBI8BTwH1VdSzJnUl2j5cdAV5Ichy4H/jrqnphrYaWpI0qVbUudzw/P1+Li4vrct+S9FYkebSq5s/lez0jTZIaGV1JamR0JamR0ZWkRkZXkhoZXUlqZHQlqZHRlaRGRleSGhldSWpkdCWpkdGVpEZGV5IaGV1JamR0JamR0ZWkRkZXkhoZXUlqZHQlqZHRlaRGRleSGhldSWpkdCWpkdGVpEZGV5IaGV1JamR0JamR0ZWkRkZXkhoZXUlqZHQlqZHRlaRGRleSGhldSWpkdCWp0aDoJtmV5OkkS0lue5N1H0xSSeanN6IkzY5Vo5vkQuAgcCOwE9iXZOcZ1l0M/BXw8LSHlKRZMeSZ7jXAUlWdqKpXgXuBPWdY92ngM8DPpzifJM2UIdHdCjw7sX1yvO//JLka2F5V33yzG0pyIMliksXl5eVfelhJ2uje8htpSS4APgd8crW1VXWoquaran5ubu6t3rUkbThDonsK2D6xvW2873UXA1cCDyR5BrgWWPDNNEl6oyHRfQTYkeSyJJuBvcDC61dW1UtVtaWqLq2qS4GjwO6qWlyTiSVpA1s1ulV1GrgVOAI8BdxXVceS3Jlk91oPKEmzZNOQRVV1GDi8Yt8dZ1l73VsfS5Jmk2ekSVIjoytJjYyuJDUyupLUyOhKUiOjK0mNjK4kNTK6ktTI6EpSI6MrSY2MriQ1MrqS1MjoSlIjoytJjYyuJDUyupLUyOhKUiOjK0mNjK4kNTK6ktTI6EpSI6MrSY2MriQ1MrqS1MjoSlIjoytJjYyuJDUyupLUyOhKUiOjK0mNjK4kNTK6ktTI6EpSI6MrSY0GRTfJriRPJ1lKctsZrv9EkuNJnkjynSTvmf6okrTxrRrdJBcCB4EbgZ3AviQ7Vyx7DJivqt8Fvg78/bQHlaRZMOSZ7jXAUlWdqKpXgXuBPZMLqur+qnp5vHkU2DbdMSVpNgyJ7lbg2Yntk+N9Z7Mf+NaZrkhyIMliksXl5eXhU0rSjJjqG2lJbgbmgc+e6fqqOlRV81U1Pzc3N827lqQNYdOANaeA7RPb28b7fkGSG4DbgQ9U1SvTGU+SZsuQZ7qPADuSXJZkM7AXWJhckOQq4IvA7qp6fvpjStJsWDW6VXUauBU4AjwF3FdVx5LcmWT3eNlngV8Hvpbk8SQLZ7k5STqvDXl5gao6DBxese+Oics3THkuSZpJnpEmSY2MriQ1MrqS1MjoSlIjoytJjYyuJDUyupLUyOhKUiOjK0mNjK4kNTK6ktTI6EpSI6MrSY2MriQ1MrqS1MjoSlIjoytJjYyuJDUyupLUyOhKUiOjK0mNjK4kNTK6ktTI6EpSI6MrSY2MriQ1MrqS1MjoSlIjoytJjYyuJDUyupLUyOhKUiOjK0mNjK4kNTK6ktRoUHST7ErydJKlJLed4fpfTfLV8fUPJ7l02oNK0ixYNbpJLgQOAjcCO4F9SXauWLYfeLGqfgv4R+Az0x5UkmbBkGe61wBLVXWiql4F7gX2rFizB/i38eWvA9cnyfTGlKTZsGnAmq3AsxPbJ4HfP9uaqjqd5CXgN4GfTi5KcgA4MN58JcmT5zL0BraFFX8m5wGP+fxwvh3zb5/rNw6J7tRU1SHgEECSxaqa77z/9eYxnx885tmXZPFcv3fIywungO0T29vG+864Jskm4B3AC+c6lCTNqiHRfQTYkeSyJJuBvcDCijULwJ+NL/8p8O9VVdMbU5Jmw6ovL4xfo70VOAJcCNxVVceS3AksVtUC8K/Al5MsAT9jFObVHHoLc29UHvP5wWOefed8vPEJqST18Yw0SWpkdCWp0ZpH93w8hXjAMX8iyfEkTyT5TpL3rMec07TaMU+s+2CSSrKhP1405HiTfGj8OB9L8pXuGadtwM/1u5Pcn+Sx8c/2Tesx5zQluSvJ82c7pyAjnx//mTyR5OpVb7Sq1uyL0RtvPwTeC2wGvgfsXLHmL4AvjC/vBb66ljOt9dfAY/4j4NfGlz92PhzzeN3FwIPAUWB+vede48d4B/AY8Bvj7Xeu99wNx3wI+Nj48k7gmfWeewrH/YfA1cCTZ7n+JuBbQIBrgYdXu821fqZ7Pp5CvOoxV9X9VfXyePMoo88+b2RDHmeATzP6fzl+3jncGhhyvLcAB6vqRYCqer55xmkbcswFvH18+R3ATxrnWxNV9SCjT2SdzR7gSzVyFLgkybve7DbXOrpnOoV469nWVNVp4PVTiDeqIcc8aT+jvyk3slWPefzPru1V9c3OwdbIkMf4cuDyJA8lOZpkV9t0a2PIMX8KuDnJSeAw8PGe0dbVL/v73nsasH5RkpuBeeAD6z3LWkpyAfA54CPrPEqnTYxeYriO0b9kHkzyO1X13+s61draB9xdVf+Q5A8YfXb/yqr6n/Ue7P+TtX6mez6eQjzkmElyA3A7sLuqXmmaba2sdswXA1cCDyR5htFrXwsb+M20IY/xSWChql6rqh8BP2AU4Y1qyDHvB+4DqKrvAm9j9B/hzLJBv++T1jq65+MpxKsec5KrgC8yCu5Gf60PVjnmqnqpqrZU1aVVdSmj17F3V9U5/6ch62zIz/U3GD3LJckWRi83nOgccsqGHPOPgesBkryPUXSXW6fstwB8ePwphmuBl6rquTf9joZ3/25i9Lf8D4Hbx/vuZPRLB6MH5mvAEvAfwHvX+x3LhmP+NvBfwOPjr4X1nnmtj3nF2gfYwJ9eGPgYh9FLKseB7wN713vmhmPeCTzE6JMNjwN/st4zT+GY7wGeA15j9K+X/cBHgY9OPM4Hx38m3x/yc+1pwJLUyDPSJKmR0ZWkRkZXkhoZXUlqZHQlqZHRlaRGRleSGv0vMzgPTpNQ3aUAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 864x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCOry7CAqrJF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "outputId": "44353cc2-53a2-40b9-b061-9bbc1c83dcbc"
      },
      "source": [
        "# 테스트 데이터 평가\n",
        "test_text_X = [row.split('\\t')[1] for row in test_text.split('\\n')[1:] if row.count('\\t') > 0]\n",
        "test_text_X = [clean_str(sentence) for sentence in test_text_X]\n",
        "sentences = [sentence.split(' ') for sentence in test_text_X]\n",
        "sentences_new = []\n",
        "for sentence in sentences:\n",
        "  sentence_new.append([word[:5] for word in sentence][:25])\n",
        "sentences = sentences_new\n",
        "\n",
        "test_X = tokenizer.texts_to_sequences(sentence)\n",
        "test_X = pad_sequences(test_X, padding='post')\n",
        "\n",
        "model.evaluate(test_X, test_Y, verbose=0)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-71-459d621c5c25>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mtest_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'post'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1354\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1355\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1356\u001b[0;31m             steps_per_execution=self._steps_per_execution)\n\u001b[0m\u001b[1;32m   1357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[1;32m   1115\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1117\u001b[0;31m         model=model)\n\u001b[0m\u001b[1;32m   1118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    280\u001b[0m             label, \", \".join(str(i.shape[0]) for i in nest.flatten(data)))\n\u001b[1;32m    281\u001b[0m       \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"Please provide data which shares the same first dimension.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m     \u001b[0mnum_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 3\n  y sizes: 50000\nPlease provide data which shares the same first dimension."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "puzVOTEuvfVY",
        "colab_type": "text"
      },
      "source": [
        "# 자연어\n",
        "조선왕조실록 데이터로 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQIaCyLEvkJL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "385930c7-fb39-4acb-ac6a-4dd94d334bc1"
      },
      "source": [
        "# 데이터 가져오기\n",
        "path_to_file = tf.keras.utils.get_file('corpus.txt', 'https://raw.githubusercontent.com/greentec/greentec.github.io/master/public/other/data/chosundynasty/corpus.txt')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://raw.githubusercontent.com/greentec/greentec.github.io/master/public/other/data/chosundynasty/corpus.txt\n",
            "62013440/62012502 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZFKvAsMwB3M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "d2328ab3-8752-4ce3-8f14-b290186b89fb"
      },
      "source": [
        "# 데이터 로드 및 확인\n",
        "train_text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "\n",
        "print('Length of text : {} characters'.format(len(train_text)))\n",
        "print()\n",
        "\n",
        "print(train_text[:100])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of text : 26265493 characters\n",
            "\n",
            "﻿태조 이성계 선대의 가계. 목조 이안사가 전주에서 삼척·의주를 거쳐 알동에 정착하다 \n",
            "태조 강헌 지인 계운 성문 신무 대왕(太祖康獻至仁啓運聖文神武大王)의 성은 이씨(李氏)요, 휘\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hhFa5m8ws4d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4832c88e-56c8-4878-b8fe-a446883d7655"
      },
      "source": [
        "# 훈련 데이터의 입력(X) 정제\n",
        "import re\n",
        "\n",
        "def clean_str(string):\n",
        "  string = re.sub(r\"[^가-힣A-Za-z0-9(),!?\\'\\`]\", \" \", string)\n",
        "  string = re.sub(r\"\\'s\", \" \\'s\", string)\n",
        "  string = re.sub(r\"\\'ve\", \" \\'ve\", string)\n",
        "  string = re.sub(r\"n\\'t\", \" n\\'t\" , string)\n",
        "  string = re.sub(r\"\\'re\", \" \\'re\" , string)\n",
        "  string = re.sub(r\"\\'d\", \" \\'d\" , string)\n",
        "  string = re.sub(r\"\\'ll\", \" \\'ll\" , string)\n",
        "  string = re.sub(r\",\", \" , \" , string)\n",
        "  string = re.sub(r\"!\", \" ! \" , string)\n",
        "  string = re.sub(r\"\\(\", \" \\( \" , string)\n",
        "  string = re.sub(r\"\\)\", \" \\) \" , string)\n",
        "  string = re.sub(r\"\\?\", \" \\? \" , string)\n",
        "  string = re.sub(r\"\\s{2,}\", \" \" , string)\n",
        "  string = re.sub(r\"\\'{2,}\", \"\\'\" , string)\n",
        "  string = re.sub(r\"\\'\", \"\" , string)\n",
        "\n",
        "  return string.lower()\n",
        "\n",
        "train_text = train_text.split('\\n')\n",
        "train_text = [clean_str(sentence) for sentence in train_text]\n",
        "train_text_X = []\n",
        "for sentence in train_text:\n",
        "  train_text_X.extend(sentence.split(' '))\n",
        "  train_text_X.append('\\n')\n",
        "\n",
        "train_text_X = [word for word in train_text_X if word != '']\n",
        "\n",
        "print(train_text_X[:20])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['태조', '이성계', '선대의', '가계', '목조', '이안사가', '전주에서', '삼척', '의주를', '거쳐', '알동에', '정착하다', '\\n', '태조', '강헌', '지인', '계운', '성문', '신무', '대왕']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xR9yO3N_x78e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "415d8121-30da-4d80-b34e-ce0576bde166"
      },
      "source": [
        "# 단어 토큰화\n",
        "vocab = sorted(set(train_text_X))\n",
        "vocab.append(\"UNK\")\n",
        "print('{} unique words'.format(len(vocab)))\n",
        "\n",
        "word2idx = {u:i for i, u in enumerate(vocab)}\n",
        "idx2word = np.array(vocab)\n",
        "\n",
        "text_as_int = np.array([word2idx[c] for c in train_text_X])\n",
        "\n",
        "print('{')\n",
        "for word, _ in zip(word2idx, range(10)):\n",
        "  print('  {:4s}: {:3d}, '.format(repr(word), word2idx[word]))\n",
        "print(' ...\\n}')\n",
        "\n",
        "print('index of UNK: {}'.format(word2idx['UNK']))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "332515 unique words\n",
            "{\n",
            "  '\\n':   0, \n",
            "  '!' :   1, \n",
            "  ',' :   2, \n",
            "  '000명으로':   3, \n",
            "  '001':   4, \n",
            "  '002':   5, \n",
            "  '003':   6, \n",
            "  '004':   7, \n",
            "  '005':   8, \n",
            "  '006':   9, \n",
            " ...\n",
            "}\n",
            "index of UNK: 332514\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQYdx7WHwF5B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "c7bbfa2f-a443-4a0a-c90a-438d28b32749"
      },
      "source": [
        "# 토큰 데이터 확인\n",
        "print(train_text_X[:20])\n",
        "print(text_as_int[:20])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['태조', '이성계', '선대의', '가계', '목조', '이안사가', '전주에서', '삼척', '의주를', '거쳐', '알동에', '정착하다', '\\n', '태조', '강헌', '지인', '계운', '성문', '신무', '대왕']\n",
            "[299181 229520 161349  17366 110944 230178 250960 154993 225348  28960\n",
            " 190192 256005      0 299181  25557 273428  36069 163902 180371  84330]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iCi_LxNwTKe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "ad7024a6-9c0d-4e2f-a33d-69ca77ce9031"
      },
      "source": [
        "# 기본 데이터세트 만들기\n",
        "seq_length = 25\n",
        "examples_per_epoch = len(text_as_int) // seq_length\n",
        "sentence_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
        "sentence_dataset = sentence_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "for item in sentence_dataset.take(1):\n",
        "  print(idx2word[item.numpy()])\n",
        "  print(item.numpy())"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['태조' '이성계' '선대의' '가계' '목조' '이안사가' '전주에서' '삼척' '의주를' '거쳐' '알동에' '정착하다'\n",
            " '\\n' '태조' '강헌' '지인' '계운' '성문' '신무' '대왕' '\\\\(' '\\\\)' '의' '성은' '이씨' '\\\\(']\n",
            "[299181 229520 161349  17366 110944 230178 250960 154993 225348  28960\n",
            " 190192 256005      0 299181  25557 273428  36069 163902 180371  84330\n",
            "  17277  17278 224068 164455 230134  17277]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_56fKUxGw5BR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "3495ce63-4fd7-4458-c59e-648aaaad9fe4"
      },
      "source": [
        "# 학습 데이터세트 만들기\n",
        "def split_input_target(chunk):\n",
        "  return [chunk[:-1], chunk[-1]]\n",
        "\n",
        "train_dataset = sentence_dataset.map(split_input_target)\n",
        "for x, y in train_dataset.take(1):\n",
        "  print(idx2word[x.numpy()])\n",
        "  print(x.numpy())\n",
        "  print(idx2word[y.numpy()])\n",
        "  print(y.numpy())"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['태조' '이성계' '선대의' '가계' '목조' '이안사가' '전주에서' '삼척' '의주를' '거쳐' '알동에' '정착하다'\n",
            " '\\n' '태조' '강헌' '지인' '계운' '성문' '신무' '대왕' '\\\\(' '\\\\)' '의' '성은' '이씨']\n",
            "[299181 229520 161349  17366 110944 230178 250960 154993 225348  28960\n",
            " 190192 256005      0 299181  25557 273428  36069 163902 180371  84330\n",
            "  17277  17278 224068 164455 230134]\n",
            "\\(\n",
            "17277\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zG2onuG33YOW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 데이터 세트 shuffle, batch 설정\n",
        "BATCH_SIZE = 128\n",
        "steps_per_epoch = examples_per_epoch\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "train_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWcdax10zBG4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "d76dbdbd-1fd6-4118-f4fb-9a8e497fa7d2"
      },
      "source": [
        "# 단어 단위 생성 모델 정의\n",
        "total_words = len(vocab)\n",
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Embedding(total_words, 100, input_length=seq_length),\n",
        "  tf.keras.layers.LSTM(units=100, return_sequences=True),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.LSTM(units=100),\n",
        "  tf.keras.layers.Dense(total_words, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 25, 100)           33251500  \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 25, 100)           80400     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 25, 100)           0         \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 100)               80400     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 332515)            33584015  \n",
            "=================================================================\n",
            "Total params: 66,996,315\n",
            "Trainable params: 66,996,315\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NewniE_r0Y8T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a4736d15-b134-4816-cd5e-d32007218e85"
      },
      "source": [
        "# 단어 단위 생성 모델 학습\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "def testmodel(epoch, logs):\n",
        "  if epoch % 5 != 0 and epoch != 49:\n",
        "    return\n",
        "  test_sentence = train_text[0]\n",
        "\n",
        "  next_words = 100\n",
        "  for _ in range(next_words):\n",
        "    test_text_X = test_sentence.split(' ')[-seq_length:]\n",
        "    test_text_X = np.array([word2idx[c] if c in word2idx else word2idx['UNK'] for c in test_text_X])\n",
        "\n",
        "    test_text_X = pad_sequences([test_text_X], maxlen=seq_length, padding='pre', value=word2idx['UNK'])\n",
        "\n",
        "    output_idx = model.predict_classes(test_text_X)\n",
        "    test_sentence += ' ' + idx2word[output_idx[0]]\n",
        "\n",
        "  print()\n",
        "  print(test_text_X)\n",
        "  print()\n",
        "\n",
        "testmodelcb = tf.keras.callbacks.LambdaCallback(on_epoch_end=testmodel)\n",
        "\n",
        "history = model.fit(train_dataset.repeat(), epochs=50, steps_per_epoch=steps_per_epoch, callbacks=[testmodelcb], verbose=2)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}