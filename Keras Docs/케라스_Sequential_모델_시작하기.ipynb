{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "케라스 Sequential 모델 시작하기.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMlRrJQ3O62lRQcR6HMLxV+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SeonHyungJo/tensorflow-2.0-study/blob/master/Keras%20Docs/%EC%BC%80%EB%9D%BC%EC%8A%A4_Sequential_%EB%AA%A8%EB%8D%B8_%EC%8B%9C%EC%9E%91%ED%95%98%EA%B8%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMZ5HsMOfD5M",
        "colab_type": "text"
      },
      "source": [
        "Sequential 모델은 레이어를 선형으로 연결하여 구성한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgOIzdNpfcgY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(32, input_shape=(784,)),\n",
        "    Activation('relu'),\n",
        "    Dense(10),\n",
        "    Activation('softmax'),\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgQuOz8qff4y",
        "colab_type": "text"
      },
      "source": [
        "또한, .add() 메소드를 통해서 쉽게 레이어를 추가 가능하다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdV64oOqflOz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(32, input_dim=784))\n",
        "model.add(Activation('relu'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TDBgtenf2d4",
        "colab_type": "text"
      },
      "source": [
        "모델에는 입력형태에 대한 정보가 필요하다. \n",
        "\n",
        "Sequential 모델의 첫번째 레이어는 입력 형태에 대한 정보를 받는다.\n",
        "두 번째 이후 레이어들은 자동으로 형태를 추정할 수 있기 때문에 형태정보는 없어도 된다.\n",
        " \n",
        "- 정수형 또는 None으로 구성된 형태 튜플의 `input_shape` 인자를 첫번째 레이어에 전달한다. 여기서 None은 음이 아닌 어떠한 정수.\n",
        "- Dense와 같은 일부 2D 레이어의 경우, 입력 형태를 input_dim 인자를 통해서 지정이 가능하다.\n",
        "- 입력 데이터에 고정된 배치 형태를 필요로 하는 경우 레이어에 batch_size인자를 넘길 수 있다. 순환 신경망에서 응용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGfOn8-zgvNG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(32, input_shape=(784,)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTGGUsHvgyFv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(32, input_dim=784))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5DAtrldg1fF",
        "colab_type": "text"
      },
      "source": [
        "# 컴파일\n",
        "\n",
        "모델을 학습시키기 전에, compile 메소드를 통해서 학습 방식에 대한 환경설정을 해야한다. \n",
        "\n",
        "세 개의 인자를 받는다.\n",
        "- optimizer : rmsprp나 adagrad와 같은 기존의 optimizer에 대한 문자열 식별자 또는 Optimizer 클래스의 인스턴스 사용가능\n",
        "- loss function : 모델이 최적화에 사용되는 목적 함수 categorical_crossentropy 또는 mse 와 같은 기존의 손실 함수의 문자열 식별자 또는 목적 함수를 사용할 수 있음\n",
        "- metric list : 분류 문제에서 metrics=['accuracy'] 기준은 문자열 식별자 또는 사용자 정의 기준 함수를 사용할 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FD-lcybQhhIN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# For a multi-class classification problem\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# For a binary classification problem\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# For a mean squared error regression problem\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='mse')\n",
        "\n",
        "# For custom metrics\n",
        "import keras.backend as K\n",
        "\n",
        "def mean_pred(y_true, y_pred):\n",
        "    return K.mean(y_pred)\n",
        "\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy', mean_pred])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8k3GDeCiWgZ",
        "colab_type": "text"
      },
      "source": [
        "# 학습\n",
        "\n",
        "케라스 모델은 입력 데이터와 라벨로 구성된 Numpy 배열 위에서 이루어진다.\n",
        "\n",
        "학습을 위해서 fit함수를 사용한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iP_tLvGhihRJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "afcb988d-209e-4dd3-b5b8-13df2d11d77f"
      },
      "source": [
        "# For a single-input model with 2 classes (binary classification):\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(32, activation='relu', input_dim=100))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Generate dummy data\n",
        "import numpy as np\n",
        "data = np.random.random((1000, 100))\n",
        "labels = np.random.randint(2, size=(1000, 1))\n",
        "\n",
        "# Train the model, iterating on the data in batches of 32 samples\n",
        "model.fit(data, labels, epochs=10, batch_size=32)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-209e2c2ce47a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# For a single-input model with 2 classes (binary classification):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sigmoid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Sequential' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxP-2qyqijBE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# For a single-input model with 10 classes (categorical classification):\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(32, activation='relu', input_dim=100))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Generate dummy data\n",
        "import numpy as np\n",
        "data = np.random.random((1000, 100))\n",
        "labels = np.random.randint(10, size=(1000, 1))\n",
        "\n",
        "# Convert labels to categorical one-hot encoding\n",
        "one_hot_labels = keras.utils.to_categorical(labels, num_classes=10)\n",
        "\n",
        "# Train the model, iterating on the data in batches of 32 samples\n",
        "model.fit(data, one_hot_labels, epochs=10, batch_size=32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9w1hHE6jI3B",
        "colab_type": "text"
      },
      "source": [
        "# 다중 클래스 소프트맥스 분류를 위한 다계층 인공 신경망 (MLP)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8I_FlV3jVUX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "# Generate dummy data\n",
        "import numpy as np\n",
        "x_train = np.random.random((1000, 20))\n",
        "y_train = keras.utils.to_categorical(np.random.randint(10, size=(1000, 1)), num_classes=10)\n",
        "x_test = np.random.random((100, 20))\n",
        "y_test = keras.utils.to_categorical(np.random.randint(10, size=(100, 1)), num_classes=10)\n",
        "\n",
        "model = Sequential()\n",
        "# Dense(64) is a fully-connected layer with 64 hidden units.\n",
        "# in the first layer, you must specify the expected input data shape:\n",
        "# here, 20-dimensional vectors.\n",
        "model.add(Dense(64, activation='relu', input_dim=20))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=sgd,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "          epochs=20,\n",
        "          batch_size=128)\n",
        "score = model.evaluate(x_test, y_test, batch_size=128)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwGEdFlwjea9",
        "colab_type": "text"
      },
      "source": [
        "# 이진 분류를 위한 MLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nMkR5qQjfFa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "\n",
        "# Generate dummy data\n",
        "x_train = np.random.random((1000, 20))\n",
        "y_train = np.random.randint(2, size=(1000, 1))\n",
        "x_test = np.random.random((100, 20))\n",
        "y_test = np.random.randint(2, size=(100, 1))\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(64, input_dim=20, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "          epochs=20,\n",
        "          batch_size=128)\n",
        "score = model.evaluate(x_test, y_test, batch_size=128)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_UrTIwbjhrE",
        "colab_type": "text"
      },
      "source": [
        "# VGG 스타일 convnet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZyPiVc1jjOY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "# Generate dummy data\n",
        "x_train = np.random.random((100, 100, 100, 3))\n",
        "y_train = keras.utils.to_categorical(np.random.randint(10, size=(100, 1)), num_classes=10)\n",
        "x_test = np.random.random((20, 100, 100, 3))\n",
        "y_test = keras.utils.to_categorical(np.random.randint(10, size=(20, 1)), num_classes=10)\n",
        "\n",
        "model = Sequential()\n",
        "# input: 100x100 images with 3 channels -> (100, 100, 3) tensors.\n",
        "# this applies 32 convolution filters of size 3x3 each.\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(100, 100, 3)))\n",
        "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=sgd)\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=32, epochs=10)\n",
        "score = model.evaluate(x_test, y_test, batch_size=32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5JC0DGsjmW2",
        "colab_type": "text"
      },
      "source": [
        "# 시퀀스 분류를 위한 LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkNJXLujjn2S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import LSTM\n",
        "\n",
        "max_features = 1024\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_features, output_dim=256))\n",
        "model.add(LSTM(128))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=16, epochs=10)\n",
        "score = model.evaluate(x_test, y_test, batch_size=16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpiROu6dklxW",
        "colab_type": "text"
      },
      "source": [
        "# 시퀀스 분류를 위한 1D 합성곱"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAb0tQKkkm0J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import Conv1D, GlobalAveragePooling1D, MaxPooling1D\n",
        "\n",
        "seq_length = 64\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv1D(64, 3, activation='relu', input_shape=(seq_length, 100)))\n",
        "model.add(Conv1D(64, 3, activation='relu'))\n",
        "model.add(MaxPooling1D(3))\n",
        "model.add(Conv1D(128, 3, activation='relu'))\n",
        "model.add(Conv1D(128, 3, activation='relu'))\n",
        "model.add(GlobalAveragePooling1D())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=16, epochs=10)\n",
        "score = model.evaluate(x_test, y_test, batch_size=16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEc6oEEPk7ZL",
        "colab_type": "text"
      },
      "source": [
        "# 시퀀스 분류를 위한 축적형 LSTM\n",
        "\n",
        "보다 고수준의 한시적 표현(temporal representation)을 학습하기 위하여 3개의 LSTM 레이어를 연결하여 사용합니다.\n",
        "\n",
        "앞의 두 LSTM은 각각의 전체 출력 시퀀스를 반환하지만, 마지막 남은 LSTM은 출력 시퀀스의 마지막 단계만을 반환합니다. 결과적으로 한시적 차원(temporal dimension)을 생략하게 됩니다. 이를테면 입력 시퀀스를 하나의 벡터로 변환합니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJu3pd3IlI82",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense\n",
        "import numpy as np\n",
        "\n",
        "data_dim = 16\n",
        "timesteps = 8\n",
        "num_classes = 10\n",
        "\n",
        "# expected input data shape: (batch_size, timesteps, data_dim)\n",
        "model = Sequential()\n",
        "model.add(LSTM(32, return_sequences=True,\n",
        "               input_shape=(timesteps, data_dim)))  # returns a sequence of vectors of dimension 32\n",
        "model.add(LSTM(32, return_sequences=True))  # returns a sequence of vectors of dimension 32\n",
        "model.add(LSTM(32))  # return a single vector of dimension 32\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Generate dummy training data\n",
        "x_train = np.random.random((1000, timesteps, data_dim))\n",
        "y_train = np.random.random((1000, num_classes))\n",
        "\n",
        "# Generate dummy validation data\n",
        "x_val = np.random.random((100, timesteps, data_dim))\n",
        "y_val = np.random.random((100, num_classes))\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=64, epochs=5,\n",
        "          validation_data=(x_val, y_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PXr-WrPldqN",
        "colab_type": "text"
      },
      "source": [
        "# 축적형 렌더링 LSTM\n",
        "\n",
        "축적형 순환 신경망(stateful recurrent model)은 배치 샘플을 처리한 후의 내부 상태를 다음 배치 샘플에 대한 초기 상태로 재사용합니다. 이를 통해서 계산 복잡도가 지나치게 높지 않게끔 유지하면서 보다 긴 시퀀스를 처리할 수 있도록 합니다. FAQ에서 축적형 LSTM에 대한 정보를 더 보실 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k76dAvzNlhos",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense\n",
        "import numpy as np\n",
        "\n",
        "data_dim = 16\n",
        "timesteps = 8\n",
        "num_classes = 10\n",
        "batch_size = 32\n",
        "\n",
        "# Expected input batch shape: (batch_size, timesteps, data_dim)\n",
        "# Note that we have to provide the full batch_input_shape since the network is stateful.\n",
        "# the sample of index i in batch k is the follow-up for the sample i in batch k-1.\n",
        "model = Sequential()\n",
        "model.add(LSTM(32, return_sequences=True, stateful=True,\n",
        "               batch_input_shape=(batch_size, timesteps, data_dim)))\n",
        "model.add(LSTM(32, return_sequences=True, stateful=True))\n",
        "model.add(LSTM(32, stateful=True))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Generate dummy training data\n",
        "x_train = np.random.random((batch_size * 10, timesteps, data_dim))\n",
        "y_train = np.random.random((batch_size * 10, num_classes))\n",
        "\n",
        "# Generate dummy validation data\n",
        "x_val = np.random.random((batch_size * 3, timesteps, data_dim))\n",
        "y_val = np.random.random((batch_size * 3, num_classes))\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size, epochs=5, shuffle=False,\n",
        "          validation_data=(x_val, y_val))\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}